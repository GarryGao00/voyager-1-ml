{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed972dbb",
   "metadata": {},
   "source": [
    "# Turn original data in to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8f5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "folder_str='./voyager1-impacts/hits'\n",
    "output_filename = './voyager1-impacts.xlsx'\n",
    "combined_filename = './voyager1-impacts-unique.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9b8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Excel workbook\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Loop through all files in the folder\n",
    "count=0\n",
    "header = ['PART#/MOD16.MOD60', 'YYYY-DDD', 'SCET TIME']\n",
    "for filename in os.listdir(folder_str):\n",
    "    # Check if the filename starts with 'v1_dust_impact_list'\n",
    "    if filename.startswith('v1_dust_impacts_list'):\n",
    "        count+=1\n",
    "        content=[]\n",
    "        # If the filename matches, open the file and do something with its contents\n",
    "        with open(os.path.join(folder_str, filename), 'r') as file:\n",
    "            sheet_name = filename[:]  # Remove the file extension from the sheet name, if any\n",
    "            worksheet = workbook.create_sheet(sheet_name)\n",
    "            worksheet.append(header)\n",
    "\n",
    "            # Read the file contents and split them into lines\n",
    "            contents = file.read()\n",
    "            lines = contents.split('\\n')\n",
    "\n",
    "            # Write each line to the current sheet\n",
    "            for i, line in enumerate(lines):\n",
    "                line = line.strip()\n",
    "                if len(line)>0 and line[0].isdigit():\n",
    "                    temp = line.split()\n",
    "                    del temp[2]\n",
    "                    content.append(temp)\n",
    "            \n",
    "            for row in content:\n",
    "                worksheet.append(row)\n",
    "\n",
    "                \n",
    "# Delete the empty sheet\n",
    "if 'Sheet' in workbook.sheetnames:\n",
    "    workbook.remove(workbook['Sheet'])\n",
    "# Save the workbook to disk\n",
    "workbook.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59659976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: v1_dust_impacts_list_may2001, len = 34\n",
      "Sheet: v1_dust_impacts_list_jun2015, len = 54\n",
      "Sheet: v1_dust_impacts_list_dec2005, len = 40\n",
      "Sheet: v1_dust_impacts_list_nov2017, len = 57\n",
      "Sheet: v1_dust_impacts_list_sep2001, len = 35\n",
      "Sheet: v1_dust_impacts_list_jun2022, len = 60\n",
      "Sheet: v1_dust_impacts_list_apr2020, len = 58\n",
      "Sheet: v1_dust_impacts_list_mar2011, len = 50\n",
      "Sheet: v1_dust_impacts_list_jan2021, len = 59\n",
      "Sheet: v1_dust_impacts_list_dec2008, len = 44\n",
      "Sheet: v1_dust_impacts_list_aug2012, len = 51\n",
      "Sheet: v1_dust_impacts_list_mar2023, len = 61\n",
      "count = 603\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a dictionary of DataFrames\n",
    "sheets = pd.read_excel(output_filename, sheet_name=None, header=0)\n",
    "count = 0\n",
    "# Loop through each sheet and print its contents\n",
    "for sheet_name, sheet_data in sheets.items():\n",
    "    sheet_len = len(sheet_data)\n",
    "    print(f'Sheet: {sheet_name}, len = {sheet_len}')\n",
    "    # print(sheet_data)\n",
    "    count+=sheet_len\n",
    "    \n",
    "print(f'count = {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c5ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PART#/MOD16.MOD60  YYYY-DDD     SCET TIME  YYYY-MM-DD\n",
      "0          2/27204.35  1980-060  00:13:38.204  1980-02-29\n",
      "1          2/27204.57  1980-060  00:31:14.204  1980-02-29\n",
      "2          2/47474.21  1982-004  16:02:18.421  1982-01-04\n",
      "3          2/51317.18  1982-132  18:23:55.054  1982-05-12\n",
      "4          2/52730.44  1982-179  21:08:33.822  1982-06-28\n",
      "..                ...       ...           ...         ...\n",
      "337        9/03774.28  2018-109  03:18:17.093  2018-04-19\n",
      "386        7/33570.41  2009-020  06:41:39.788  2009-01-20\n",
      "387        7/47311.11  2010-113  07:05:36.061  2010-04-23\n",
      "490        7/21911.11  2007-362  15:05:40.351  2007-12-28\n",
      "602        9/45289.11  2022-031  23:03:45.769  2022-01-31\n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine all sheets into a single DataFrame\n",
    "combined_data = pd.concat(sheets.values(), ignore_index=True)\n",
    "combined_data.drop_duplicates(inplace = True)\n",
    "# add new YYYY-MM-DD column\n",
    "combined_data['YYYY-MM-DD'] = pd.to_datetime(combined_data['YYYY-DDD'], format='%Y-%j').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d274371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to the Excel file\n",
    "with pd.ExcelWriter(combined_filename) as writer:\n",
    "    combined_data.to_excel(writer, sheet_name='combined_data', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8101b40",
   "metadata": {},
   "source": [
    "# Use the modified data (more accurate sclk time obtained from gif images) to get cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c31eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import spacepy.pycdf as pycdf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time as tm\n",
    "\n",
    "data_folder_path = './voyager-1-pws-wf/data'\n",
    "excel_str = './voyager1-impacts/voyager1-impacts-unique-modified-v2.xlsx' # more accurate version\n",
    "cleaned_filename = './voyager1-impacts/voyager1-impacts-unique-cleaned.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79024b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PART#/MOD16.MOD60  YYYY-DDD     SCET TIME  YYYY-MM-DD\n",
      "0     2/27204.35.719  1980-060  00:13:38.204  1980-02-29\n",
      "1     2/27204.57.170  1980-060  00:31:14.204  1980-02-29\n",
      "2     2/47474.21.145  1982-004  16:02:18.421  1982-01-04\n",
      "3     2/51317.18.425  1982-132  18:23:55.054  1982-05-12\n",
      "4     2/52730.44.334  1982-179  21:08:33.822  1982-06-28\n",
      "..               ...       ...           ...         ...\n",
      "72    8/58809.58.342  2017-124  02:54:27.387  2017-05-04\n",
      "74    9/03774.28.239  2018-109  03:18:17.093  2018-04-19\n",
      "76    9/31227.11.188  2020-294  05:28:07.055  2020-10-20\n",
      "77    9/44163.43.223  2021-359  10:41:23.424  2021-12-25\n",
      "78    9/45289.11.653  2022-031  23:03:45.769  2022-01-31\n",
      "\n",
      "[61 rows x 4 columns]\n",
      "Index(['PART#/MOD16.MOD60', 'YYYY-DDD', 'SCET TIME', 'YYYY-MM-DD'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a dictionary of DataFrames\n",
    "sheets = pd.read_excel(excel_str, sheet_name='combined_data', header=0)\n",
    "sheets = sheets.drop_duplicates(subset=[sheets.columns[0]])\n",
    "print(sheets)\n",
    "print(sheets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c295cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "['/Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/data/1980/vg1_pws_wf_1980-02-29T00_v1.0.cdf']\n"
     ]
    }
   ],
   "source": [
    "# file path stores all the cdf files that contains a hit KV: {'YYYY-MM-DD': [PATH1, ...]}\n",
    "file_paths={}\n",
    "\n",
    "# traverse through sclk time\n",
    "for index, row in sheets.iterrows():\n",
    "    # get the useful information and find the name of the subdirectory\n",
    "    acc_sclk = row['PART#/MOD16.MOD60']\n",
    "    date_str = row['YYYY-MM-DD']\n",
    "    year = date_str[:4]\n",
    "    # check if sclk time is completed\n",
    "    if len(acc_sclk)>11:\n",
    "        year_folder_path = os.path.join(data_folder_path, year)\n",
    "        # Loop through all files in the directory\n",
    "        temp = [] # temp folder to store all the paths\n",
    "        for file_name in os.listdir(year_folder_path):\n",
    "            # Check if the file name contains the date string and ends with '.cdf'\n",
    "            if date_str in file_name and file_name.endswith('.cdf'):\n",
    "                # If found, print the full path to the file\n",
    "                file_path = os.path.join(year_folder_path, file_name)\n",
    "                temp.append(file_path)\n",
    "                \n",
    "            file_paths[date_str] = temp    \n",
    "        \n",
    "\n",
    "print(len(file_paths))\n",
    "print(file_paths['1980-02-29'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f766de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PART#/MOD16.MOD60  YYYY-DDD     SCET TIME  YYYY-MM-DD         new scet  \\\n",
      "0     2/27204.35.719  1980-060  00:13:38.204  1980-02-29  00:14:21.283999   \n",
      "1     2/27204.57.170  1980-060  00:31:14.204  1980-02-29  00:31:24.344000   \n",
      "2     2/47474.21.145  1982-004  16:02:18.421  1982-01-04  16:02:27.061000   \n",
      "3     2/51317.18.425  1982-132  18:23:55.054  1982-05-12  18:24:20.494000   \n",
      "4     2/52730.44.334  1982-179  21:08:33.822  1982-06-28  21:08:53.802000   \n",
      "..               ...       ...           ...         ...              ...   \n",
      "72    8/58809.58.342  2017-124  02:54:27.387  2017-05-04  02:54:45.847000   \n",
      "74    9/03774.28.239  2018-109  03:18:17.093  2018-04-19  03:18:29.411000   \n",
      "76    9/31227.11.188  2020-294  05:28:07.055  2020-10-20  05:28:16.274999   \n",
      "77    9/44163.43.223  2021-359  10:41:23.424  2021-12-25  10:41:34.743999   \n",
      "78    9/45289.11.653  2022-031  23:03:45.769  2022-01-31  23:04:22.888999   \n",
      "\n",
      "             diffs  indexs                                     cdf_file_paths  \n",
      "0   0:00:43.079999   14331  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "1   0:00:10.140000   31379  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "2   0:00:08.640000     307  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "3   0:00:25.440000    2811  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "4   0:00:19.980000    1118  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "..             ...     ...                                                ...  \n",
      "72  0:00:18.460000      70  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "74  0:00:12.318000      49  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "76  0:00:09.219999      33  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "77  0:00:11.319999      40  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "78  0:00:37.119999     132  /Volumes/Garrys_T7/Voyager/voyager-1-pws-wf/da...  \n",
      "\n",
      "[61 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# add a new column named 'new scet'\n",
    "new_scet = []\n",
    "# add a new column named 'diffs' for the difference between scet and new scet diff = new scet - scet\n",
    "diffs = []\n",
    "# add a new column named 'indexs' for index references\n",
    "indexs = []\n",
    "# add a new column named 'cdf_file_paths'\n",
    "cdf_file_paths = [] \n",
    "\n",
    "for ind, row in sheets.iterrows():\n",
    "    # loop through rows to get the date and scet time\n",
    "    date_str = row['YYYY-MM-DD']\n",
    "    acc_sclk = row['PART#/MOD16.MOD60'].split('/')[1].replace('.', ':')\n",
    "    scet = row['SCET TIME']\n",
    "    dt = datetime.strptime(f\"{date_str} {scet}\", '%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    # find the path and extract the information\n",
    "    file_path_lst = file_paths[date_str]\n",
    "    # init values that could not exist\n",
    "    index, temp_scet, diff, cdf_file_path = 'NA', 'NA', 'NA', file_path_lst\n",
    "    # loop through different cdf files until we find the closest time stamp\n",
    "    for num in range(len(file_path_lst)):\n",
    "        file_path = file_path_lst[num]\n",
    "        cdf = pycdf.CDF(file_path)\n",
    "        time = cdf['Epoch'][:]\n",
    "        part = cdf['Part'][:]\n",
    "        sclk = cdf['SCLK'][:].tolist()\n",
    "        ### BAD PRACTICE - Convert to INT in order to compar\n",
    "        sclk_int = [int(s.replace(':', '')) for s in sclk]\n",
    "        waveform = cdf['Waveform'][:]\n",
    "        time_offsets = cdf['timeOffsets'][:]\n",
    "\n",
    "        # check if acc_time is in range\n",
    "        sclk_head, sclk_tail = sclk_int[0], sclk_int[-1]\n",
    "        ### BAD PRACTICE - Convert to INT in order to compare\n",
    "        acc_sclk_int = int(acc_sclk.replace(':', ''))\n",
    "        # Check if acc_time is between head and tail time\n",
    "        if sclk_head <= acc_sclk_int <= sclk_tail:\n",
    "            # Find the closest datetime object in the list\n",
    "            closest_int = min(sclk_int, key=lambda x: abs(acc_sclk_int-x))\n",
    "            # Find the index of the closest datetime object in the list\n",
    "            index = sclk_int.index(closest_int)\n",
    "            # Get values from index\n",
    "            temp_scet = time[index]\n",
    "            diff = str(temp_scet - dt)\n",
    "            temp_scet = temp_scet.strftime('%H:%M:%S.%f')\n",
    "            cdf_file_path = file_path\n",
    "#             # find unmatched frames\n",
    "#             if acc_sclk_int - sclk_int[index] != 0:\n",
    "#                 print(f'date={date_str}, sclk1={sclk[index-1]}, ori_sclk2={sclk[index]}, sclk3={sclk[index+1]}')\n",
    "#                 print(f'data = {acc_sclk}, index = {index}')\n",
    "#                 print(f'file_path = {file_path}')\n",
    "            # add new info to the list   \n",
    "            indexs.append(index)\n",
    "            new_scet.append(temp_scet)\n",
    "            diffs.append(diff)\n",
    "            cdf_file_paths.append(cdf_file_path)\n",
    "            \n",
    "sheets['new scet'] = new_scet\n",
    "sheets['diffs'] = diffs\n",
    "sheets['indexs'] = indexs\n",
    "sheets['cdf_file_paths'] = cdf_file_paths\n",
    "print(sheets)\n",
    "with pd.ExcelWriter(cleaned_filename) as writer:\n",
    "    sheets.to_excel(writer, sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39004281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
