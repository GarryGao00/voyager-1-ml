{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b732a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4c271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ignore this block\n",
    "# # test data block, generate data for testing usage\n",
    "# # generate random values in [-1, 1] range. 30 values in one array and ttl i_size arrays\n",
    "# i_size = 2000\n",
    "# x = torch.rand(i_size, 150) * 2 - 1  \n",
    "# y = torch.zeros(i_size)\n",
    "# y[x.sum(dim=1) > 0] = 1  # set y to 1 where x sum is positive\n",
    "# print(\"Input tensor x shape:\", x.shape)\n",
    "# print(\"Output tensor y shape:\", y.shape)\n",
    "# print(\"First 5 elements of x:\")\n",
    "# print(x[:5].sum(dim=1))\n",
    "# print(\"First 5 elements of y:\")\n",
    "# print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d941c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit_arr: (122, 1600)\n",
      "non_hit_arr: (244, 1600)\n"
     ]
    }
   ],
   "source": [
    "# read in hit and non_hit csv files\n",
    "hit_csv_str = './voyager-1-ml/hit.csv'\n",
    "non_hit_csv_str = '.voyager-1-ml/non_hit.csv'\n",
    "\n",
    "hit_arr = np.genfromtxt(hit_csv_str, delimiter=',')\n",
    "non_hit_arr = np.genfromtxt(non_hit_csv_str, delimiter=',')\n",
    "\n",
    "# Print the arrays\n",
    "print('hit_arr:', hit_arr.shape)\n",
    "print('non_hit_arr:', non_hit_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1535341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # form test set and training set\n",
    "# test_fraction = 0.1\n",
    "\n",
    "# # Get the number of rows in the arrays\n",
    "# hit_num_rows, non_num_rows = hit_arr.shape[0], non_hit_arr.shape[0]\n",
    "\n",
    "# # Shuffle the indices of the rows in each array\n",
    "# hit_idx = np.random.permutation(hit_num_rows)\n",
    "# non_idx = np.random.permutation(non_num_rows)\n",
    "\n",
    "# # Get the indices for the test set and the training set\n",
    "# hit_num_test = int(hit_num_rows * test_fraction)\n",
    "# non_num_test = int(non_num_rows * test_fraction)\n",
    "# hit_test_idx = hit_idx[:hit_num_test]\n",
    "# hit_train_idx = hit_idx[hit_num_test:]\n",
    "# non_test_idx = non_idx[:non_num_test]\n",
    "# non_train_idx = non_idx[non_num_test:]\n",
    "\n",
    "# # Split the arrays into test and training sets\n",
    "# hit_arr_test = hit_arr[hit_test_idx]\n",
    "# hit_arr_test_y = np.ones(hit_arr_test.shape[0])\n",
    "# hit_arr_train = hit_arr[hit_train_idx]\n",
    "# hit_arr_train_y = np.ones(hit_arr_train.shape[0])\n",
    "\n",
    "# non_hit_arr_test = non_hit_arr[non_test_idx]\n",
    "# non_hit_arr_test_y = np.zeros(non_hit_arr_test.shape[0])\n",
    "# non_hit_arr_train = non_hit_arr[non_train_idx]\n",
    "# non_hit_arr_train_y = np.zeros(non_hit_arr_train.shape[0])\n",
    "\n",
    "# print(f'hit_test shape: {hit_arr_test.shape}')\n",
    "# print(f'hit_train shape: {hit_arr_train.shape}')\n",
    "# print(f'non_hit_train shape: {non_hit_arr_train.shape}')\n",
    "# print(f'non_hit_test shape: {non_hit_arr_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672a9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form test set and training set\n",
    "test_fraction = 0.05\n",
    "train_fraction = 1-test_fraction\n",
    "\n",
    "# Get the number the test and train size of each\n",
    "hit_train_size = int(train_fraction * len(hit_arr))\n",
    "hit_test_size = len(hit_arr) - hit_train_size\n",
    "non_hit_train_size = int(train_fraction * len(non_hit_arr))\n",
    "non_hit_test_size = len(non_hit_arr) - non_hit_train_size\n",
    "\n",
    "# Split both sets\n",
    "hit_train_dataset, hit_test_dataset = torch.utils.data.random_split(hit_arr, [hit_train_size,hit_test_size])\n",
    "non_hit_train_dataset, non_hit_test_dataset = torch.utils.data.random_split(non_hit_arr, [non_hit_train_size, non_hit_test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b768ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape = torch.Size([20, 1600]), x shape = torch.Size([346, 1600]), y_test shape = torch.Size([20]), y shape = torch.Size([346])\n",
      "len(y_test) = 20, y_test = tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# combine the training set and test set\n",
    "x_test_arr = np.concatenate((hit_test_dataset,non_hit_test_dataset), axis=0)\n",
    "x_arr = np.concatenate((hit_train_dataset,non_hit_train_dataset), axis=0)\n",
    "x_test = torch.Tensor(x_test_arr)\n",
    "x = torch.Tensor(x_arr)\n",
    "\n",
    "y_test_arr = np.concatenate((np.ones(hit_test_size),np.zeros(non_hit_test_size)))\n",
    "y_arr = np.concatenate((np.ones(hit_train_size),np.zeros(non_hit_train_size)))\n",
    "y_test = torch.Tensor(y_test_arr)\n",
    "y = torch.Tensor(y_arr)\n",
    "\n",
    "print('x_test shape = {}, x shape = {}, y_test shape = {}, y shape = {}'.format(x_test.shape, x.shape, y_test.shape, y.shape))\n",
    "print(f'len(y_test) = {len(y_test)}, y_test = {y_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7bea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine the training set and test set\n",
    "# x_test_arr = np.concatenate((hit_arr_test,non_hit_arr_test), axis=0)\n",
    "# x_arr = np.concatenate((hit_arr_train,non_hit_arr_train), axis=0)\n",
    "# x_test = torch.Tensor(x_test_arr)\n",
    "# x = torch.Tensor(x_arr)\n",
    "\n",
    "# y_test_arr = np.concatenate((hit_arr_test_y,non_hit_arr_test_y), axis=0)\n",
    "# y_arr = np.concatenate((hit_arr_train_y,non_hit_arr_train_y), axis=0)\n",
    "# y_test = torch.Tensor(y_test_arr)\n",
    "# y = torch.Tensor(y_arr)\n",
    "\n",
    "# print('x_test shape = {}, x shape = {}, y_test shape = {}, y shape = {}'.format(x_test.shape, x.shape, y_test.shape, y.shape))\n",
    "# print(f'len(y_test) = {len(y_test)}, y_test = {y_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382afe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1600, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1600, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = Net()\n",
    "\n",
    "# Print the model's architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ae9157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: Loss = 0.6352, Recall = 0.0000\n",
      "Epoch 1999: Loss = 0.6345, Recall = 0.0000\n",
      "Epoch 2999: Loss = 0.6335, Recall = 0.0000\n",
      "Epoch 3999: Loss = 0.6315, Recall = 0.0000\n",
      "Epoch 4999: Loss = 0.6272, Recall = 0.0000\n",
      "Epoch 5999: Loss = 0.6146, Recall = 0.0000\n",
      "Epoch 6999: Loss = 0.5650, Recall = 0.0000\n",
      "Epoch 7999: Loss = 0.3975, Recall = 0.5913\n",
      "Epoch 8999: Loss = 0.1759, Recall = 0.8870\n",
      "Epoch 9999: Loss = 0.0522, Recall = 0.9913\n",
      "Epoch 10999: Loss = 0.0211, Recall = 1.0000\n",
      "Epoch 11999: Loss = 0.0120, Recall = 1.0000\n",
      "Epoch 12999: Loss = 0.0080, Recall = 1.0000\n",
      "Epoch 13999: Loss = 0.0059, Recall = 1.0000\n",
      "Epoch 14999: Loss = 0.0046, Recall = 1.0000\n",
      "Epoch 15999: Loss = 0.0037, Recall = 1.0000\n",
      "Epoch 16999: Loss = 0.0031, Recall = 1.0000\n",
      "Epoch 17999: Loss = 0.0027, Recall = 1.0000\n",
      "Epoch 18999: Loss = 0.0023, Recall = 1.0000\n",
      "Epoch 19999: Loss = 0.0021, Recall = 1.0000\n",
      "Epoch 20999: Loss = 0.0019, Recall = 1.0000\n",
      "Epoch 21999: Loss = 0.0017, Recall = 1.0000\n",
      "Epoch 22999: Loss = 0.0015, Recall = 1.0000\n",
      "Epoch 23999: Loss = 0.0014, Recall = 1.0000\n",
      "Epoch 24999: Loss = 0.0013, Recall = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the neural network model\n",
    "model = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(25000):\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute the loss and recall\n",
    "    loss = criterion(y_pred.squeeze(), y)\n",
    "    y_pred_binary = torch.round(y_pred.detach()).squeeze().cpu().numpy()\n",
    "    recall = recall_score(y.cpu().numpy(), y_pred_binary, average='binary')\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss and recall every 1000 epochs\n",
    "    if epoch % 1000 == 999:\n",
    "        print(\"Epoch {}: Loss = {:.4f}, Recall = {:.4f}\".format(epoch, loss.item(), recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c44746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ignore this block \n",
    "# # Test unit for test data block\n",
    "\n",
    "# # Create input tensor x_test\n",
    "# x_test = torch.rand(2000, 150) * 2 - 1  # generate random values in [-1, 1] range\n",
    "\n",
    "# # Load the trained model\n",
    "# model = model\n",
    "\n",
    "# # Test the model on the example inputs\n",
    "# with torch.no_grad():\n",
    "#     y_test = model(x_test)\n",
    "#     y_pred = torch.round(y_test).squeeze().tolist()\n",
    "\n",
    "# # Print the predictions\n",
    "# # print(\"Input tensor x_test:\")\n",
    "# # print(x_test.sum(dim=1))\n",
    "# # print(\"Predicted output tensor y_pred:\")\n",
    "# # print(y_pred)\n",
    "\n",
    "# # Calculate the accuracy of the predictions\n",
    "# y_true = [1 if x.sum() > 0 else 0 for x in x_test]\n",
    "# correct = sum([1 if y_pred[i] == y_true[i] else 0 for i in range(len(y_pred))])\n",
    "# accuracy = correct / len(y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1b3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.029  0.4071 0.9967 0.9966 0.0004 0.0008 0.0006 0.0425 0.0041 0.0008\n",
      "  0.0136 0.3331 0.0006 0.0025 0.0002 0.0009 0.0008 0.0003 0.0031 0.0031]]\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "length of test: 20\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Test unit\n",
    "\n",
    "# load test dataset and the model\n",
    "x_test = x_test\n",
    "y_test = y_test\n",
    "model = model\n",
    "\n",
    "# Test the model on the example inputs\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)\n",
    "    y_pred_binary = torch.round(y_pred).squeeze().tolist()\n",
    "\n",
    "# Print the predictions\n",
    "# print(\"Input tensor x_test:\")\n",
    "# print(x_test.sum(dim=1))\n",
    "# print(\"Predicted output tensor y_pred:\")\n",
    "# print(y_pred)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "y_pred_binary=torch.tensor(y_pred_binary)\n",
    "# convert to NumPy array and set print options\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "y_pred_np = y_pred.T.numpy()\n",
    "print(y_pred_np)\n",
    "print(y_pred_binary)\n",
    "print(y_test)\n",
    "print(f'length of test: {len(y_test)}')\n",
    "\n",
    "accuracy = torch.sum(y_pred_binary == y_test).float() / len(y_test)\n",
    "print('Test accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6c164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "# save the model :D\n",
    "model = model\n",
    "path = 'voyager_dust_impact_4layer_model_v1.pt'\n",
    "torch.save(model.state_dict(), path)\n",
    "print('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831ec99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
